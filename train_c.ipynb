{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkQD6nMy8xQg",
        "outputId": "251b34e4-585d-4690-e008-d7bbd1e0cab5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# 모듈이 있는 디렉토리의 절대 경로 가져오기\n",
        "module_dir = '/content/drive/MyDrive/pythondeep'\n",
        "\n",
        "# Python 경로에 디렉토리 추가\n",
        "sys.path.append(module_dir)"
      ],
      "metadata": {
        "id": "JCU2-KOG8y8Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from scipy.io import loadmat\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "from model_ import boReEsNet, ReEsNet # 외부 설정한 모델 불러옴\n",
        "\n",
        "# 파일 경로 설정\n",
        "file_path_Xt = '/content/drive/My Drive/pythondeep/data/XTrain_RSRP.mat'\n",
        "file_path_Yt = '/content/drive/My Drive/pythondeep/data/YTrain_RSRP.mat'\n",
        "file_path_Xv = '/content/drive/My Drive/pythondeep/data/XValidation_RSRP.mat'\n",
        "file_path_Yv = '/content/drive/My Drive/pythondeep/data/YValidation_RSRP.mat'\n",
        "\n",
        "# .mat 파일 읽기\n",
        "data_Xt = loadmat(file_path_Xt)\n",
        "data_Yt = loadmat(file_path_Yt)\n",
        "data_Xv = loadmat(file_path_Xv)\n",
        "data_Yv = loadmat(file_path_Yv)\n",
        "\n",
        "# 데이터 불러오기\n",
        "X_train = torch.tensor(data_Xt['XTrain_RSRP'], dtype=torch.float32)\n",
        "Y_train = torch.tensor(data_Yt['YTrain_RSRP'], dtype=torch.float32)\n",
        "\n",
        "X_val = torch.tensor(data_Xv['XValidation_RSRP'], dtype=torch.float32)\n",
        "Y_val = torch.tensor(data_Yv['YValidation_RSRP'], dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "uUIao9o-66P-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Dataset과 DataLoader 설정\n",
        "X_train = X_train.permute(3,2,0,1)\n",
        "Y_train = Y_train.permute(3,2,0,1)\n",
        "X_val = X_val.permute(3,2,0,1)\n",
        "Y_val = Y_val.permute(3,2,0,1)\n",
        "\n",
        "# data shape 확인\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(Y_val.shape)\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "# DataLoader 생성\n",
        "batch_size = 128\n",
        "train_dataset = CustomDataset(X_train, Y_train)\n",
        "val_dataset = CustomDataset(X_val, Y_val)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 모델 초기화\n",
        "input_channels = X_train.shape[1]  # 입력 채널 크기\n",
        "num_filters = 8                    # N_filter 값\n",
        "num_classes = Y_train.shape[1] if len(Y_train.shape) > 1 else 1  # 출력 크기\n",
        "model = boReEsNet(input_channels=input_channels, num_filters=num_filters, num_classes=num_classes)\n",
        "# model2 = ReEsNet(input_channels = input_channels, num_filters=num_filters, num_classes=num_classes)\n",
        "\n",
        "# 손실 함수와 옵티마이저 설정\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.001)  # L2Regularization = weight_decay\n",
        "\n",
        "# 학습률 스케줄러 설정\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)  # LearnRateDropPeriod, LearnRateDropFactor\n",
        "\n",
        "# 학습 설정\n",
        "# num_epochs = 100\n",
        "num_epochs = 5\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "# 학습 루프\n",
        "train_loss_history = []\n",
        "val_loss_history = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2T6vbVy7Fl9",
        "outputId": "271a8576-53f1-48dc-c3d6-6ff52731ff1d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([124375, 2, 24, 2])\n",
            "torch.Size([124375, 2, 72, 14])\n",
            "torch.Size([625, 2, 24, 2])\n",
            "torch.Size([625, 2, 72, 14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 모델 초기화\n",
        "model1 = boReEsNet(input_channels=2, num_filters=8, num_classes=2).to(device)\n",
        "model2 = ReEsNet(input_channels=2, num_filters=8, num_classes=2).to(device)\n",
        "\n",
        "# 손실 함수\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# 옵티마이저\n",
        "optimizer = torch.optim.Adam(\n",
        "    list(model1.parameters()) + list(model2.parameters()),  # 두 모델의 파라미터를 함께 최적화\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "# 학습률 스케줄러\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "# 손실 기록\n",
        "train_loss_history1, val_loss_history1 = [], []\n",
        "train_loss_history2, val_loss_history2 = [], []\n",
        "\n",
        "# 학습 루프\n",
        "for epoch in range(num_epochs):\n",
        "    model1.train()\n",
        "    model2.train()\n",
        "    running_loss1, running_loss2 = 0.0, 0.0\n",
        "\n",
        "    for i, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Forward, loss calculation\n",
        "        outputs1 = model1(inputs)\n",
        "        outputs2 = model2(inputs)\n",
        "        loss1 = criterion(outputs1, targets)\n",
        "        loss2 = criterion(outputs2, targets)\n",
        "\n",
        "        # Backward, optimization\n",
        "        optimizer.zero_grad()\n",
        "        (loss1 + loss2).backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss1 += loss1.item()\n",
        "        running_loss2 += loss2.item()\n",
        "\n",
        "    # Epoch당 학습 손실 계산\n",
        "    train_loss1 = running_loss1 / len(train_loader)\n",
        "    train_loss2 = running_loss2 / len(train_loader)\n",
        "    train_loss_history1.append(train_loss1)\n",
        "    train_loss_history2.append(train_loss2)\n",
        "\n",
        "    # 검증 루프\n",
        "    model1.eval()\n",
        "    model2.eval()\n",
        "    val_loss1, val_loss2 = 0.0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for val_inputs, val_targets in val_loader:\n",
        "            val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
        "\n",
        "            # Validation loss\n",
        "            val_outputs1 = model1(val_inputs)\n",
        "            val_outputs2 = model2(val_inputs)\n",
        "            val_loss1 += criterion(val_outputs1, val_targets).item()\n",
        "            val_loss2 += criterion(val_outputs2, val_targets).item()\n",
        "\n",
        "    # Epoch당 검증 손실 계산\n",
        "    val_loss1 /= len(val_loader)\n",
        "    val_loss2 /= len(val_loader)\n",
        "    val_loss_history1.append(val_loss1)\n",
        "    val_loss_history2.append(val_loss2)\n",
        "\n",
        "    # Epoch마다 결과 출력\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "    print(f\"Model 1 - Train Loss: {train_loss1:.4f}, Validation Loss: {val_loss1:.4f}\")\n",
        "    print(f\"Model 2 - Train Loss: {train_loss2:.4f}, Validation Loss: {val_loss2:.4f}\")\n",
        "\n",
        "    # 학습률 스케줄러 업데이트\n",
        "    scheduler.step()\n",
        "\n",
        "# 학습된 모델 저장\n",
        "torch.save(model1.state_dict(), 'boReEsNet12.pth')\n",
        "torch.save(model2.state_dict(), 'ReEsNet12.pth')\n"
      ],
      "metadata": {
        "id": "ZK4TC_wQetEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8716cb6-b484-45f0-dd72-b69c1cc355d2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]\n",
            "Model 1 - Train Loss: 0.0144, Validation Loss: 0.0056\n",
            "Model 2 - Train Loss: 0.0190, Validation Loss: 0.0174\n",
            "Epoch [2/5]\n",
            "Model 1 - Train Loss: 0.0057, Validation Loss: 0.0041\n",
            "Model 2 - Train Loss: 0.0083, Validation Loss: 0.0145\n",
            "Epoch [3/5]\n",
            "Model 1 - Train Loss: 0.0050, Validation Loss: 0.0067\n",
            "Model 2 - Train Loss: 0.0076, Validation Loss: 0.0233\n",
            "Epoch [4/5]\n",
            "Model 1 - Train Loss: 0.0049, Validation Loss: 0.0033\n",
            "Model 2 - Train Loss: 0.0073, Validation Loss: 0.0189\n",
            "Epoch [5/5]\n",
            "Model 1 - Train Loss: 0.0048, Validation Loss: 0.0037\n",
            "Model 2 - Train Loss: 0.0071, Validation Loss: 0.0150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- out of memory가 났다 그래서 데이터 shape를 일치시키는 데 우여곡절이 있엇음\n",
        "- 학습 로스가 에포크 초반에도 줄지 않아 학습이 안되는 것처럼 보엿음\n",
        "- 데이터 쉐입이 매트랩이랑 토치랑 달랏고\n",
        "- 채널이 2엿는데 24로 넣었고\n",
        "- dilated에서 패딩 세임에ㅓㅅ 2*dilation 수정\n",
        "- transpose쪽 stride도\n",
        "- 배치 사이즈 변경해보고\n",
        "- 배치 정규화 추가해보고\n",
        "- 에폭 줄이고\n",
        "- 스텝 사이즈 줄이고\n",
        "- 왜냐면 오버피팅 같아서 학습은 로스 주는데 검증은 늘어남"
      ],
      "metadata": {
        "id": "ycTghgv4Mzd7"
      }
    }
  ]
}